\documentclass{article}
% generated by Madoko, version 1.0.0-rc5
%mdk-data-line={1}


\usepackage[heading-base={2},section-num={False},bib-label={True}]{madoko2}


\begin{document}



%mdk-data-line={1}
\noindent\mdline{1}\% Homework 4%mdk
%mdk-data-line={4}

\newcommand{\zo}{\{0,1\}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\getsr}{\leftarrow_R\;}
%mdk-data-line={11}
\subsubsection{\mdline{11}0.0.1.\hspace*{0.5em}\mdline{11}Total of 130 points}\label{sec-total-of-130-points}%mdk%mdk

%mdk-data-line={13}
\noindent\mdline{13}The following two questions show that a PRF does \mdline{13}\emph{not}\mdline{13} necessarily yield a cryptographic hash function that can be used as a proof of work or provide collision resistance.%mdk

%mdk-data-line={15}
\begin{enumerate}%mdk

%mdk-data-line={15}
\item{}
%mdk-data-line={15}
\mdline{15}(15 points) Show (under the PRF conjecture) that there exists a PRF \mdline{15}$\{ f_k \}$\mdline{15} mapping \mdline{15}$n$\mdline{15} bits to \mdline{15}$n$\mdline{15} bits and an efficient algorithm \mdline{15}$A$\mdline{15} such that
\mdline{16}$A(k)=x$\mdline{16} such that \mdline{16}$f_k(x)=0^\ell$\mdline{16}.%mdk

%mdk-data-line={17}
\begin{mdbmarginx}{1ex}{0pt}{1ex}{0pt}%mdk
%mdk-data-line={18}
\noindent\mdline{18}\textbf{Proof}.  \mdline{18} We beging by constructing an artificially \mdline{18}\textquotedblleft{}weak\textquotedblright{}\mdline{18}"\mdline{18} PRF \mdline{18}$\{f_k \}$\mdline{18} family mapping \mdline{18}$n$\mdline{18} bits to \mdline{18}$n$\mdline{18}
 bits which is nonetheless still a secure PRF. Given an arbitrary PRF \mdline{19}$\{g_k \}$\mdline{19} family, define 
 the new PRF \mdline{20}$\{f_k \}$\mdline{20} family as \mdline{20}$f_k(x) = g_k(x)$\mdline{20} for \mdline{20}$x \neq k$\mdline{20} and \mdline{20}$f_k(x) = 0^l$\mdline{20} for \mdline{20}$x = k$\mdline{20}.
 Then intuitively, note that we\mdline{21}\textquoteleft{}ve changed only a single output for each fixed function $g_k$
 and therefore, because $k$ is unknown to the adversary, then if $g_k(x)$ behaves like a random 
 function, then so does $f_k(x)$. The only input on which it does not behave randomly is $x =k$,
 and so an adversary could distinguish between $g_k$ and $f_k$ if he correctly gives input
 $x = k$, however, given that $k \in_R \zo^n$, the likelihood of this happening is $\frac{1}{2^n}$, 
 which is negligible. Therefore, the PRF $\{f_k \}$ is secure.
 
 However, note that now we can construct an efficient algorithm $A$ with the required properties
 that allows us to find a collision.  Simply define $A(k) = k$, which is constant time. Then it
 is immediately clear that \$f\textquoteright{}\mdline{30}\_\mdline{30}k(k) = 0\mdline{30}\textasciicircum{}\mdline{30}n\mdline{30}\$\mdline{30}.%mdk%mdk
\end{mdbmarginx}%mdk%mdk

%mdk-data-line={33}
\item{}
%mdk-data-line={33}
\mdline{33}(15 points) Show (under the PRF conjecture) that there exists a PRF \mdline{33}$\{ f_k \}$\mdline{33} mapping \mdline{33}$n$\mdline{33} bits to \mdline{33}$n$\mdline{33} bits and an efficient algorithm \mdline{33}$A$\mdline{33} such that
\mdline{34}$A(k)=(x,x')$\mdline{34} such that \mdline{34}$f_k(x)=f_k(x')$\mdline{34}.%mdk

%mdk-data-line={35}
\begin{mdbmarginx}{1ex}{0pt}{1ex}{0pt}%mdk
%mdk-data-line={36}
\noindent\mdline{36}\textbf{Proof}.  \mdline{36}  We take a very similar approach to the above to construct a PRF with the desired properties.
  Given an arbitrary PRF \mdline{37}$\{g_k \}$\mdline{37} family, define the PRF \mdline{37}$\{f_k \}$\mdline{37} family as follows: \mdline{37}$f_k(x) = g_k(x)$\mdline{37}
  for \mdline{38}$x \neq k$\mdline{38} and \mdline{38}$f_k(k) = g_k(k+1)$\mdline{38}. Then note that \mdline{38}$f_k$\mdline{38} differs from \mdline{38}$g_k$\mdline{38} on a single 
  output, and therefore its distribution can only be distinguished from \mdline{39}$g_k$\mdline{39} if an adversary
  picks as input either \mdline{40}$k$\mdline{40} or \mdline{40}$k+1$\mdline{40}, which occurs with probability at most \mdline{40}$\frac{1}{2^{n-1}}$\mdline{40} 
  because \mdline{41}$k \in_R \zo^n$\mdline{41}. Therefore, the PRF \mdline{41}$\{f_k\}$\mdline{41} is secure if \mdline{41}$\{g_k \}$\mdline{41} is secure.
\mdline{42}\mdbr
\mdline{43}  However, we can now construsct the adversary \mdline{43}$A(k) = (k, k+1)$\mdline{43} and by construction, it is
  immediately clear that \mdline{44}$f_k(k) = g_k(k+1) = f_k(k+1)$\mdline{44}.%mdk%mdk
\end{mdbmarginx}%mdk%mdk
%mdk
\end{enumerate}%mdk

%mdk-data-line={48}
\begin{enumerate}[noitemsep,topsep=\mdcompacttopsep,start=3]%mdk

%mdk-data-line={48}
\item\mdline{48}(20 points) This question studies the security implications of including a unique \mdline{48}\textquotedblleft{}salt\textquotedblright{}\mdline{48} value per user when hashing passwords.
Suppose that \mdline{49}$H$\mdline{49} is a random oracle, and an adversary is given a database \mdline{49}$(y_1,\ldots,y_N)$\mdline{49} of the hashes of passwords of \mdline{49}$N$\mdline{49} users, with each user choosing their
password at random from a dictionary \mdline{50}$D$\mdline{50}. Compute (up to an order of magnitude)
the expected number of queries (as a function of \mdline{51}$N$\mdline{51} and \mdline{51}$|D|$\mdline{51})  an adversary needs to make to recover the passwords for all users in the case (a) that the \mdline{51}$i^{th}$\mdline{51}  entry in the database is simply \mdline{51}$H(p_i)$\mdline{51} where \mdline{51}$p_i$\mdline{51} is the password of the \mdline{51}$i^{th}$\mdline{51} user and the case (b) that the \mdline{51}$i^{th}$\mdline{51} entry is \mdline{51}$s_i\|H(s_i\|p_i)$\mdline{51} where \mdline{51}$s_i$\mdline{51} is a \mdline{51}\textquotedblleft{}salt\textquotedblright{}\mdline{51} value chosen at random in \mdline{51}$\zo^n$\mdline{51}.
 

%mdk-data-line={53}
\begin{enumerate}[noitemsep,topsep=\mdcompacttopsep,label=\alph*.]%mdk

%mdk-data-line={53}
\item\mdline{53}We make the assumption that each of the \mdline{53}$y_i$\mdline{53} are distinct. Note that 
we can do this without loss of generality since repeated \mdline{54}$y_i$\mdline{54} give no additional information
to the adversary. In the first case, we have \mdline{55}$y_i = H(p_i)$\mdline{55}. Let \mdline{55}$X$\mdline{55} be the expected number
of queries an 
adversary needs to recover the passwords for all users in the database. Note that because 
\mdline{58}$H$\mdline{58} is completely random, the adversary has no choice but to linearly search through the
space \mdline{59}$D$\mdline{59} in order to find the passwords. Therefore, we pick some random permutation of \mdline{59}$D$\mdline{59}
and select that as the search pattern for the adversary. Then let \mdline{60}$X_i$\mdline{60} be the number of
queries needed to recover \mdline{61}$p_i$\mdline{61}, and note that \mdline{61}$X_i$\mdline{61} is precisely equivalent to the index
of \mdline{62}$p_i$\mdline{62} in the permutation chosen by the adversary for searching. Due to the fact that 
the passwords are chosen at random, we have \mdline{63}$X_i \stackrel{i.i.d}{\sim} \text{DUnif}(1,|D|)$\mdline{63},
and therefore we have \mdline{64}$X = \max_{i=1}^N\{ X_i \}$\mdline{64}. Now that we have the above, we wish 
to calculate \mdline{65}$E[X]$\mdline{65}. First, recall the CDF for \mdline{65}$X_i$\mdline{65}:
\noindent\noindent\[%mdk-data-line={67}
\Pr[X_i \leq k ] = \frac{k}{|D|}
\]%mdk
\mdline{69}Then note that we can calculate the PDF of \mdline{69}$X$\mdline{69} as follows:
\noindent\noindent\[%mdk-data-line={71}
\begin{aligned}
\Pr[X \leq k-1] + \Pr[X \geq k+1] + \Pr[X = k] &= 1 \\
\implies \Pr[X = k] &= 1 - \Pr[X \leq k - 1] - \Pr[X \geq k + 1] \\
&= \Pr[X \leq k] - \Pr[X \leq k - 1] \\
&= (\Pr[X_i \leq k])^n - (\Pr[X_i \leq k - 1])^n \\
&= \frac{k^N - (k-1)^N}{|D|}    
\end{aligned}
\]%mdk
\mdline{79}Then we can use the definition of expected value to calculate our final result:
\noindent\noindent\[%mdk-data-line={81}
\begin{aligned}
E[X] &= \sum_{k=1}^{|D|} k \frac{k^N - (k-1)^N}{|D|}   \\
&= \frac{1}{|D|} \sum_{k=1}^{|D|} k^{N+1} - k(k-1)^N 
\end{aligned}
\]%mdk
\mdline{86}At this point I\mdline{86}'\mdline{86}m basically stuck, so I instead I opt for an approximation to the solution by
converting from discrete to uniform. Let \mdline{87}$Y_i \stackrel{i.i.d}{\sim} \text{Unif}(0,|D|)$\mdline{87} and
create a mapping where \mdline{88}$X_i = \lceil Y_i \rceil$\mdline{88} so that we can use experiments on \mdline{88}$Y_i$\mdline{88}
to simulate experiments on \mdline{89}$X_i$\mdline{89}. Then note that 
\mdline{90}$X = \max_i \{X_i \} = \max_i \{ \lceil Y_i \rceil \} = \lceil \max_i \{ Y_i \} \rceil$\mdline{90}, so 
let \mdline{91}$Y = \max \{Y_i \}$\mdline{91} and let us explore the properties of \mdline{91}$Y$\mdline{91} just like we did with \mdline{91}$X$\mdline{91}. 
First, let\mdline{92}'\mdline{92}s calculate the CDF of \mdline{92}$Y$\mdline{92} (noting that the CDF for \mdline{92}$Y_i$\mdline{92} is \mdline{92}$F_{Y_i}(y) = \frac{y}{|D|}$\mdline{92})
\noindent\noindent\[%mdk-data-line={94}
\begin{aligned}
F_Y(y) &= F_{Y_i}(y)^N \\
&= \frac{y^n}{|D|^N}
\end{aligned}
\]%mdk
\mdline{99}Then we can immediately calculate the PDF as \mdline{99}$f_Y(y) = \frac{Ny^{N-1}}{|D|^N}$\mdline{99}, and armed with
this result, we can calculate the expected value:
\noindent\noindent\[%mdk-data-line={102}
\begin{aligned}
E[Y] &= \frac{N}{|D|^N} \int_0^{|D|} y^n \\
&= \frac{N}{(N+1)|D|^N}y^{n+1} \biggr|_0^{|D|}\\
&= \frac{N}{N+1}|D|
\end{aligned}
\]%mdk
\mdline{108}From the above we can deduce that for large \mdline{108}$N$\mdline{108}:
\noindent\noindent\[%mdk-data-line={110}
E[X] \approx |D| 
\]%mdk

%mdk-data-line={112}
\mdline{112}Therefore we expect the adversary to make approximately \mdline{112}$|D|$\mdline{112} queries before get gets all 
the passwords.%mdk%mdk

%mdk-data-line={115}
\item\mdline{115}We make the assumption that each of the \mdline{115}$y_i$\mdline{115} are distinct, as before. Therefore, we 
have \mdline{116}$y_i = s_i || H(s_i || p_i)$\mdline{116} distinct. Note that given \mdline{116}$y_i$\mdline{116}, the 
attacker knows \mdline{117}$s_i$\mdline{117} (the salt). However, the beauty of the salt in this case is that 
because a different salt is used for each user (see note below), then the attacker must
launch a new attack on each hash. Intuitively, hashes with salt \mdline{119}$s_i$\mdline{119} give no information
about hashes with salt \mdline{120}$s_j$\mdline{120} for \mdline{120}$i \neq j$\mdline{120}. More formally, let \mdline{120}$X$\mdline{120} be the number of 
queries an adversary needs to make to recover the passwords for all users. Then note 
that \mdline{122}$X = \sum_{i=1}^N X_i$\mdline{122} where \mdline{122}$X_i$\mdline{122} is the number of queries needed to recover \mdline{122}$p_i$\mdline{122} 
Because each query on a distinct salt is independent of other queries, we have that
\mdline{124}$X_i \stackrel{i.i.d}{\sim} \text{DUnif}(1,|D|)$\mdline{124}. We can imagine arranging the set \mdline{124}$D$\mdline{124} in 
some permutation through which the adversary will sequentially guess. Then note that \mdline{125}$X_i$\mdline{125}
is equivalent to the index of \mdline{126}$p_i$\mdline{126} in this permutation, therefore it is distributed 
uniformly over the support. Then note that \mdline{127}$E[X_i] = \frac{|D| + 1}{2}$\mdline{127} which results in:
\noindent\noindent\[%mdk-data-line={129}
E[X] = \sum_{i=1}^N E[X_i] = \sum_{i=1}^N \frac{|D| + 1}{2} = \frac{N(|D| + 1)}{2} 
\]%mdk
\mdline{134}Note that above we made the assumption that the \mdline{134}$s_i$\mdline{134} were distinct. If this is not the 
case, then an attacker can take advantage of the duplicity in seeds to improve his attack 
(similar to the results in part (a) where now he can attack all hashes which share a salt
at the same time), which means that technically speaking, the above
is an upper bound on the number of queries. However, note that if we make the assumption 
that \mdline{139}$N << 2^{n/2}$\mdline{139},
then by the birthday problem, the likelihood of having a collision in the \mdline{140}$s_i$\mdline{140} is 
negligibly low and it is safe to assume that the \mdline{141}$s_i$\mdline{141} are distinct. Furthermore, security
can be improved by making sure that our system never reuses a seed, even in the case where
\mdline{143}$N >> 2^{n/2}$\mdline{143}. A final point, even if the above is not true, note that part (a) gives us 
a lower bound on the expected number of queries necessariy. Therefore, technically speaking,
with no assumptions, all we can say is that th expected number of queries \mdline{145}$E(X)$\mdline{145} satisfies:
\noindent\noindent\[%mdk-data-line={147}
|D| \leq E(X) \leq \frac{N(|D| + 1)}{2} 
\]%mdk%mdk
%mdk
\end{enumerate}%mdk%mdk
%mdk
\end{enumerate}%mdk

%mdk-data-line={152}
\begin{enumerate}[,start=4]%mdk

%mdk-data-line={152}
\item{}
%mdk-data-line={152}
\mdline{152}(30 points) Consider the following construction \mdline{152}$(S,V)$\mdline{152} for a message authentication code: given some hash function collection \mdline{152}$\{ h_k \}$\mdline{152}, to sign the message \mdline{152}$m$\mdline{152} the signing algorithm  \mdline{152}$S_k(m)$\mdline{152} outputs a \mdline{152}\mdcode{C}\mdline{152}  program \mdline{152}$P$\mdline{152} that on input \mdline{152}$k,m$\mdline{152}    outputs the constant \mdline{152}$y=h_k(m)$\mdline{152}. The verification algorithm \mdline{152}$V$\mdline{152} on key \mdline{152}$k$\mdline{152} and pair \mdline{152}$(m,P)$\mdline{152} outputs \mdline{152}$1$\mdline{152} iff \mdline{152}$P(k,m)=h_k(m)$\mdline{152}.%mdk

%mdk-data-line={154}
\begin{enumerate}[,label=\alph*.]%mdk

%mdk-data-line={154}
\item{}
%mdk-data-line={154}
\mdline{154}(15 points) Prove that \mdline{154}$(S,V)$\mdline{154} is secure in the random oracle model. That is, prove that with high probability if \mdline{154}$H$\mdline{154} is a random function and the function \mdline{154}$h_k(m)$\mdline{154} is defined as \mdline{154}$H(k\|m)$\mdline{154} then there is no adversary that succeeds in a chosen message attack against \mdline{154}$(S,V)$\mdline{154}.%mdk

%mdk-data-line={155}
\begin{mdbmarginx}{1ex}{0pt}{1ex}{0pt}%mdk
%mdk-data-line={156}
\noindent\mdline{156}\textbf{Proof}.  \mdline{156}We proof by contradiction. Suppose such an adversary \mdline{156}$A$\mdline{156} exists which after querying the 
signature oracle \mdline{157}$T$\mdline{157} times for some polynomial \mdline{157}$T$\mdline{157} can construct a message and signature pair
\mdline{158}$(m',P')$\mdline{158} such that it verifies successfully with some \mdline{158}$p(n)$\mdline{158} non-negligible probability. 
Then we will use this adversary to construct an adversary \mdline{159}$A'$\mdline{159} that can predict the output
of \mdline{160}$H$\mdline{160} for some \mdline{160}$x'$\mdline{160} unqueried with non-negligible probability.%mdk

%mdk-data-line={162}
\mdline{162}The adversary \mdline{162}$A'$\mdline{162} has access to a completely random oracle, \mdline{162}$H$\mdline{162}, and the begins to simulate
the chosen message attack performed by \mdline{163}$A$\mdline{163}. When \mdline{163}$A$\mdline{163} queries for an signature, \mdline{163}$A'$\mdline{163} intercepts
the message \mdline{164}$m$\mdline{164}. Using a pre-picked \mdline{164}$k \in_R \zo^n$\mdline{164}, \mdline{164}$A'$\mdline{164} requests the result of \mdline{164}$y = H(k || m)$\mdline{164}
and then constructs the trivial C program \mdline{165}$P$\mdline{165} which on every input returns \mdline{165}$y$\mdline{165}. The program
is then given to \mdline{166}$A$\mdline{166}. After \mdline{166}$T$\mdline{166} such requests, \mdline{166}$A$\mdline{166} will produce a tuple \mdline{166}$(m',P')$\mdline{166} such that
for \mdline{167}$m'$\mdline{167} unqueried such that \mdline{167}$P'$\mdline{167} is a valid tag for \mdline{167}$m'$\mdline{167} with non-negligible probability 
\mdline{168}$p(n)$\mdline{168}. Then note that \mdline{168}$A'$\mdline{168} then runs \mdline{168}$P'$\mdline{168} to produce \mdline{168}$y' = P'(k,m')$\mdline{168} and proceeds to output
\mdline{169}$(k || m', y')$\mdline{169} which, with high likelihood, is a correct prediction of \mdline{169}$H$\mdline{169}. 
Formally:%mdk%mdk
\end{mdbmarginx}%mdk
\noindent\noindent\[%mdk-data-line={173}
\begin{aligned}
\Pr[H(k || m') = y'] &= \Pr[h_k(m') = P'(k,m')] \\
&= \Pr[V_k(m,P) = 1] \\
&= p(n)
\end{aligned}
\]%mdk

%mdk-data-line={179}
\mdline{179}which is non-negligible. Therefore, without querying input \mdline{179}$x' = k || m'$\mdline{179}, \mdline{179}$A$\mdline{179} is able to
predict with non-negligible probability the results of \mdline{180}$H$\mdline{180}, contradicting the fact that it is
a random function. Therefore, the adversary \mdline{181}$A$\mdline{181} cannot exist and it must be the case that \mdline{181}$(S,V)$\mdline{181} is secure in the
ranodm oracle model.%mdk%mdk

%mdk-data-line={184}
\item{}
%mdk-data-line={184}
\mdline{184}(15 points) Prove that \mdline{184}$(S,V)$\mdline{184} is \mdline{184}\emph{insecure}\mdline{184} no matter \mdline{184}\emph{what}\mdline{184} hash function collection \mdline{184}$\{ h_k \}$\mdline{184} we use as long as the map \mdline{184}$(k,m)\mapsto h_k(m)$\mdline{184} is efficiently computable.%mdk

%mdk-data-line={186}
\mdline{186}This is one example of the potential dangers in the \mdline{186}\textquotedblleft{}random oracle heuristic\textquotedblright{}\mdline{186}. Stronger examples were given by\mdline{186}~\href{https://eprint.iacr.org/1998/011.pdf}{this paper of Canneti, Goldreich and Halevi}\mdline{186}. The conclusions (Section 6) of this paper are particularly worth reading. While the technical contents of the paper are unambiguous, the three authors each had different opinions on their \mdline{186}\emph{meaning}\mdline{186} and so each author wrote his own conclusions.%mdk

%mdk-data-line={188}
\begin{mdbmarginx}{1ex}{0pt}{1ex}{0pt}%mdk
%mdk-data-line={189}
\noindent\mdline{189}\textbf{Proof}.  \mdline{189}We proof by construction. The adversary works as follows. It select random \mdline{189}$m'$\mdline{189} and then 
creates a C program \mdline{190}$P'$\mdline{190} which on input \mdline{190}$k,m$\mdline{190} uses the key to construct the hash function
\mdline{191}$h_k$\mdline{191} and then computes \mdline{191}$h_k(m)$\mdline{191} and returns that value. 
Note that \mdline{192}$P$\mdline{192} is efficiently computable as long as \mdline{192}$h_k$\mdline{192}
is efficiently computable. Then note that \mdline{193}$P'$\mdline{193} is a universal signature. For any message, it
is the case that \mdline{194}$(m,P')$\mdline{194} will be validated by the verification algorithm since by 
construction of \mdline{195}$P'$\mdline{195}, we will have that \mdline{195}$P'(k,m) = h_k(m)$\mdline{195}. Therefore, the adversary
succeeds with probability \mdline{196}$1$\mdline{196} no matter what has function collection we use as long as
the map \mdline{197}$(k,m) \mapsto h_k(m)$\mdline{197} (ie, constructing the hash function on the fly given a key and 
message, which is what \mdline{198}$P'$\mdline{198} does) is efficiently computable.%mdk%mdk
\end{mdbmarginx}%mdk%mdk
%mdk
\end{enumerate}%mdk%mdk

%mdk-data-line={201}
\item{}
%mdk-data-line={201}
\mdline{201}(20 points) This question studies the need to use \mdline{201}\emph{min entropy}\mdline{201} as opposed to \mdline{201}\emph{Shannon entropy}\mdline{201} in cryptographic applications:%mdk

%mdk-data-line={203}
\begin{enumerate}[,label=\alph*.]%mdk

%mdk-data-line={203}
\item{}
%mdk-data-line={203}
\mdline{203}(10 points) Show that there exists a distribution \mdline{203}$X$\mdline{203} over \mdline{203}$\zo^\ell$\mdline{203} such that \mdline{203}$H_{Shannon}(X) \geq \ell/100$\mdline{203} but \mdline{203}$H_{\infty}(X) \leq 5$\mdline{203}.%mdk

%mdk-data-line={204}
\begin{mdbmarginx}{1ex}{0pt}{1ex}{0pt}%mdk
%mdk-data-line={205}
\noindent\mdline{205}\textbf{Proof}.  \mdline{205}We show by construction. Take \mdline{205}$X$\mdline{205} to be a distribution over \mdline{205}$\zo^\ell$\mdline{205} where we choose with
probability \mdline{206}$2^{-c_2}$\mdline{206} some fixed string \mdline{206}$x' \in \zo^\ell$\mdline{206} and with probability \mdline{206}$1 - 2^{-c_2}$\mdline{206} we chose 
a string uniformly at random from a subset \mdline{207}$S \subset \zo^\ell \setminus \{x'\}$\mdline{207} such that \mdline{207}$|S| = 2^{c_1 \ell}$\mdline{207}
for some constants \mdline{208}$c_1 \geq 0, c_2 \in [0,1]$\mdline{208}. We never chose the strings \mdline{208}$x \in (\zo^l \setminus S) \setminus \{x'\}$\mdline{208}.
Furthermore, let us impose the constraint that \mdline{209}$2^{-c_2} \geq \frac{1-2^{-c_2}}{|S|} \implies2^{-c_2} \geq \frac{1}{1 + |S|} \implies c_2 \leq -\log \frac{1}{1 + |S|} \implies c_2 \leq \log(1 + 2^{c_1 \ell})$\mdline{211}.%mdk

%mdk-data-line={213}
\mdline{213}With the above set, note that the minimum entropy
of this distribution is precisely \mdline{214}$c_2$\mdline{214}. More formally:%mdk%mdk
\end{mdbmarginx}%mdk
\noindent\noindent\[%mdk-data-line={217}
\begin{aligned}
H_{\infty}(X) &= \min_x \left\{\log \frac{1}{\Pr[X = x]} \right\} \\
&= \log \frac{1}{\Pr[X = x']} \\
&= \log 2^{c_2} \\
&= c_2
\end{aligned}
\]%mdk

%mdk-data-line={224}
\mdline{224}The key above occurs when calculating the min. At that step, we note that by the constraint
imposed, the most likely string to occur is precisely \mdline{225}$x'$\mdline{225} since it occurs with probability
\mdline{226}$2^{-c_2}$\mdline{226} and all others strings in the support occurs with probability \mdline{226}$\frac{1-2^{-c_2}}{|S|}$\mdline{226}
since they are chosen uniformly at random. Now let us calculate the Shannon Entropy of the 
above distributions:%mdk
\noindent\noindent\[%mdk-data-line={230}
\begin{aligned}
H_{Shannon}(X) &= \sum_{x \in X} \Pr[X = x] \log \frac{1}{\Pr[X = x]} \\
&= 2^{-c_2}c_2 + \sum_{x \in S}\frac{1-2^{-c_2}}{|S|} \log \frac{|S|}{1 - 2^{-c_2}} \\
&= 2^{-c_2}c_2 + \frac{1-2^{-c_2}}{|S|} [\log(|S|) - \log (1 - 2^{-c_2})] \sum_{x \in S} 1 \\
&= 2^{-c_2}c_2 + (1-2^{c_2})(c_1\ell - \log(1 - 2^{-c_2}))
\end{aligned}
\]%mdk

%mdk-data-line={237}
\mdline{237}Then note that we just need to find \mdline{237}$c_1$\mdline{237} and \mdline{237}$c_2$\mdline{237} to satisfy the following requirements:%mdk
\noindent\noindent\[%mdk-data-line={239}
\begin{aligned}
1 \leq c_2 &\leq 5 \\
c_1 &\geq \frac{1}{50}
\end{aligned}
\]%mdk

%mdk-data-line={244}
\mdline{244}With the above constants, we will have that \mdline{244}$H_{\infty}(X) = c_2 \leq 5$\mdline{244} yet:%mdk
\noindent\noindent\[%mdk-data-line={246}
\begin{aligned}
H_{Shannon}(X) &= \frac{1}{2^{c_2}} + (1 - \frac{1}{2^{c_2}})[c_1 \ell - \log [1 - \frac{1}{2^{c_2}}]] \\
&\geq \frac{1}{2}c_1 \ell \\
&\geq \frac{1}{100}\ell
\end{aligned}
\]%mdk

%mdk-data-line={252}
\mdline{252}as desired. The second line follows from the fac tthat \mdline{252}$1- \frac{1}{2^{c_2}}$\mdline{252} is at least 
\mdline{253}$\frac{1}{2}$\mdline{253} and that \mdline{253}$c_1\ell - \log[1-\frac{1}{2^{c_2}}]$\mdline{253} is at least \mdline{253}$c_1\ell$\mdline{253}.%mdk%mdk

%mdk-data-line={255}
\item{}
%mdk-data-line={255}
\mdline{255}(10 points) Show that for \mdline{255}\emph{every}\mdline{255} distribution \mdline{255}$X \over \zo^{10n}$\mdline{255} with \mdline{255}$H_{\infty}(X)\leq 5$\mdline{255} and for \mdline{255}\emph{every}\mdline{255} salt value \mdline{255}$s\in\zo^n$\mdline{255}, and \mdline{255}\emph{every}\mdline{255} efficiently computable function \mdline{255}$h:\zo^{10n}\rightarrow\zo^n$\mdline{255} there is an efficient attacker \mdline{255}$A$\mdline{255} and a pair of messages \mdline{255}$m_0,m_1\in\zo^n$\mdline{255} such that given the salt value \mdline{255}$s$\mdline{255}, \mdline{255}$A$\mdline{255} can distinguish between a sample from \mdline{255}$h(s\|X)\oplus m_0$\mdline{255} and a sample from \mdline{255}$h(s\|X)\oplus m_1$\mdline{255} with advantage at least \mdline{255}$1/100$\mdline{255}. That is, it is impossible to use a distribution with small min entropy to obtain a secure instantiation of the one time pad.%mdk

%mdk-data-line={256}
\begin{mdbmarginx}{1ex}{0pt}{1ex}{0pt}%mdk
%mdk-data-line={257}
\noindent\mdline{257}\textbf{Proof}.  \mdline{257}We proof by construction. Suppose we have the stated distribution whose min-entropy is at most
\mdline{258}$5$\mdline{258}. First, note that there exists \mdline{258}$x'$\mdline{258} in the support such that:%mdk%mdk
\end{mdbmarginx}%mdk
\noindent\noindent\[%mdk-data-line={261}
\Pr[X = x'] = \frac{1}{2^5}
\]%mdk

%mdk-data-line={263}
\mdline{263}The above follows almost immediately from the definition of min-entropy, since we have:%mdk
\noindent\noindent\[%mdk-data-line={265}
\begin{aligned}
H_{\infty}(X) = \min_x \{\log \frac{1}{\Pr[X = x]} \} = 5 \\
\implies \exists x' \text{ st. } \log \frac{1}{\Pr[X= x']} = 5 \\
\implies  \exists x' \text{ st. } \Pr[X = x'] = \frac{1}{2^5}
\end{aligned}
\]%mdk

%mdk-data-line={271}
\mdline{271}Then we construct the adversary \mdline{271}$A$\mdline{271} as follows:%mdk

%mdk-data-line={272}
\begin{enumerate}[noitemsep,topsep=\mdcompacttopsep]%mdk

%mdk-data-line={272}
\item\mdline{272}On input \mdline{272}$1^n$\mdline{272}, the adversary first calculates the value \mdline{272}$y = h(s || x')$\mdline{272}, which it 
can do because \mdline{273}$s$\mdline{273} is given and \mdline{273}$x'$\mdline{273} exists as shown above. Practically, we can imagine
that \mdline{274}$A$\mdline{274} samples the distribution \mdline{274}$X$\mdline{274} some number of times in order to obtain the value
\mdline{275}$x'$\mdline{275} which occurs the most often. We need only do this if \mdline{275}$A$\mdline{275} does not have a description
of the distribution \mdline{276}$X$\mdline{276}. Note that in either scenario, given that \mdline{276}$x'$\mdline{276} occurs with 
probability \mdline{277}$\frac{1}{2^5}$\mdline{277}, we can pre-compute the value \mdline{277}$x'$\mdline{277} with extremely high 
probabiltiy in a constant number of cycles. Therefore, we ignore this problem and 
simply assume that \mdline{279}$A$\mdline{279} knows \mdline{279}$x'$\mdline{279}.%mdk

%mdk-data-line={280}
\item\mdline{280}The adversary then selects the messages \mdline{280}$m_0  = y$\mdline{280} and \mdline{280}$m_1 = y \oplus 1^n$\mdline{280} on which to
be tested.%mdk

%mdk-data-line={282}
\item\mdline{282}On obtaining \mdline{282}$c = h(s || X) \oplus m_b$\mdline{282}, \mdline{282}$A$\mdline{282} does the following. If \mdline{282}$c = 0^n$\mdline{282}, it outputs
\mdline{283}$0$\mdline{283}. If \mdline{283}$c = 1^n$\mdline{283}, it outputs \mdline{283}$1$\mdline{283}. Otherwise, it outputs \mdline{283}$b' \in_R \zo$\mdline{283}.%mdk
%mdk
\end{enumerate}%mdk

%mdk-data-line={285}
\mdline{285}We now show that \mdline{285}$A$\mdline{285} will guess \mdline{285}$b$\mdline{285} successfully with high probability. There are two 
scenarios to consider, depending on whether \mdline{286}$X = x'$\mdline{286} or \mdline{286}$X \neq x'$\mdline{286}.%mdk

%mdk-data-line={287}
\begin{enumerate}[noitemsep,topsep=\mdcompacttopsep]%mdk

%mdk-data-line={287}
\item\mdline{287}In the case where \mdline{287}$X = x'$\mdline{287}, the adversary always guesses correctly. This is because
\mdline{288}$c = 0^n$\mdline{288} iff \mdline{288}$m_b = m_0$\mdline{288} and \mdline{288}$c = 1^n$\mdline{288} iff and \mdline{288}$m_b = m_1$\mdline{288}.%mdk

%mdk-data-line={289}
\item\mdline{289}In the case where \mdline{289}$X \neq x'$\mdline{289}, we can essentially consider \mdline{289}$h(s || x)$\mdline{289} to be uniformly
distributed. Therefore \mdline{290}$c$\mdline{290} is uniformly distributed, and the adversary guesses 
correctly with probability \mdline{291}$\frac{1}{2} + negl(n)$\mdline{291}.%mdk
%mdk
\end{enumerate}%mdk

%mdk-data-line={293}
\mdline{293}Putting the two cases above together, we have that the probability of success is:%mdk
\noindent\noindent\[%mdk-data-line={295}
\begin{aligned}
\Pr[b' = b] &= \Pr[b' = b \mid X = x']\Pr[X = x'] + \Pr[b' = b \mid X \neq x']\Pr[X \neq x'] \\
&= (1)\frac{1}{2^5} + [\frac{1}{2} + negl(n)]\frac{2^5 - 1}{2^5} \\
&= \frac{1}{2} + \frac{2^5 - 1}{2^5}negl(n) + \frac{1}{2^6} \\
&= \frac{1}{2} + p(n)
\end{aligned}
\]%mdk

%mdk-data-line={302}
\mdline{302}where \mdline{302}$p(n)$\mdline{302} is non-negligible since it is at least the constant value \mdline{302}$\frac{1}{2^6}$\mdline{302}. Therefore
the adversary succeeds in distinguishing between the two messages with non-negligiblel 
probability, so it successfully distinguishes between a sample from \mdline{304}$h(s|| X) \oplus m_0$\mdline{304} and
\mdline{305}$h(s || X) \oplus m_1$\mdline{305}.   \mdline{305} \mdline{305}%mdk%mdk
%mdk
\end{enumerate}%mdk%mdk
%mdk
\end{enumerate}%mdk

%mdk-data-line={308}
\begin{enumerate}[,start=6]%mdk

%mdk-data-line={308}
\item{}
%mdk-data-line={308}
\mdline{308}(30 points) We now show a few properties of min entropy, many of those hold for other entropies as well:%mdk

%mdk-data-line={310}
\begin{enumerate}[noitemsep,topsep=\mdcompacttopsep,label=\alph*.]%mdk

%mdk-data-line={310}
\item\mdline{310}(10 points) Show that the min entropy function is \mdline{310}\emph{concave}\mdline{310}: that is for every two distributions \mdline{310}$X$\mdline{310} and \mdline{310}$Y$\mdline{310} and \mdline{310}$p\in [0,1]$\mdline{310}, \mdline{310}$H_{\infty}(pX+(1-p)Y)\geq pH_{\infty}(X)+(1-p)H_{\infty}(Y)$\mdline{310}, where the distribution \mdline{310}$pX+(1-p)Y$\mdline{310} is obtained by taking this combination of the vectors of probabilities or, equivalently, choosing with probability \mdline{310}$p$\mdline{310} to sample from \mdline{310}$X$\mdline{310} and with probability \mdline{310}$1-p$\mdline{310} to sample from \mdline{310}$Y$\mdline{310}. Note that this makes intuitive sense since if \mdline{310}$X$\mdline{310} and \mdline{310}$Y$\mdline{310} have a certain amount of uncertainty, we introduce only more uncertainty by choosing which one of them to sample from at random.

%mdk-data-line={311}
\begin{mdbmarginx}{1ex}{0pt}{1ex}{0pt}%mdk
%mdk-data-line={312}
\noindent\mdline{312}\textbf{Proof}.  \mdline{312}We can show this almost directly using the definition of min-entropy.%mdk%mdk
\end{mdbmarginx}%mdk%mdk

%mdk-data-line={314}
\item\mdline{314}(10 points) We have mentioned that in practical applications sometimes  operating systems accumulates an \mdline{314}\emph{entropy pool}\mdline{314} before refreshing the generator state. One approach is to simply XOR the hash of the new measurements into the old pool.
This can sometimes be problematic but let us show that under the (not always realistic) assumption of \mdline{315}\emph{independence}\mdline{315} it at least does not hurt: show that for every two distributions \mdline{315}$X$\mdline{315} and \mdline{315}$Y$\mdline{315} over \mdline{315}$\zo^n$\mdline{315}, \mdline{315}$H_{\infty}(X \oplus Y) \geq \max \{ H_{\infty}(X) , H_{\infty}(Y) \}$\mdline{315} where \mdline{315}$X\oplus Y$\mdline{315} denotes the distribution obtained by picking independently \mdline{315}$x\getsr X$\mdline{315} and \mdline{315}$y\getsr Y$\mdline{315} and outputting \mdline{315}$x\oplus y$\mdline{315}.

%mdk-data-line={316}
\begin{mdbmarginx}{1ex}{0pt}{1ex}{0pt}%mdk
%mdk-data-line={317}
\noindent\mdline{317}\textbf{Proof}.  \mdline{317}We prove directly, Let us consider the min-entropy of the \mdline{317}$X \oplus Y$\mdline{317} distribution. We carefully
simplify each step:%mdk%mdk
\end{mdbmarginx}%mdk
\noindent\noindent\[%mdk-data-line={321}
\begin{aligned}
H_{\infty}(X \oplus Y) &= \min_z \left\{\log \frac{1}{\Pr[X \oplus Y = z]} \right\} \\
&= \log \min_z \left\{ \frac{1}{\Pr[X \oplus Y = z]}\right\} \\
&= \log \frac{1}{\max_z \left\{ \Pr[X \oplus Y = z]\right\}}
\end{aligned}
\]%mdk
\mdline{327}by a similar line of reasoning, we also have that:
\noindent\noindent\[%mdk-data-line={329}
H_{\infty}(X) = \log \frac{1}{\max_x \left\{ \Pr[X = x] \right\}}
\]%mdk
\mdline{331}Therefore, if we seek to prove that \mdline{331}$H_{\infty}(X \oplus Y) \geq H_{\infty}(X)$\mdline{331}, we must show
that \mdline{332}$\max_z \left\{ \Pr[X \oplus Y = z]\right\} \leq  \max_x \left\{ \Pr[X = x] \right\}$\mdline{332}. We
can do this easily by conditioning on \mdline{333}$Y$\mdline{333}:
\noindent\noindent\[%mdk-data-line={335}
\begin{aligned}
\max_z \left\{ \Pr[X \oplus Y = z]\right\} &= \max_z \left\{ \sum_y \Pr[X \oplus y = z \mid Y=y]\Pr[Y = y]\right\} \\
&= \max_z \left\{ \sum_y \Pr[X = z \oplus y \mid Y=y]\Pr[Y = y]\right\} \\
&\leq \max_z \left\{ \sum_y  \max_x \left\{ \Pr[X = x] \right\} \Pr[Y = y]\right\} \\
&= \max_x \left\{ \Pr[X = x] \right\} \max_z \left\{ \sum_y \Pr[Y = y]\right\} \\
&= \max_x \left\{ \Pr[X = x] \right\}
\end{aligned} 
\]%mdk
\mdline{343}and therefore we conclude that \mdline{343}$H_{\infty}(X \oplus Y) \geq H_{\infty}(X)$\mdline{343}. A simpler line of 
reasoning, though less techincal, is that \mdline{344}$H_{\infty}(X \oplus Y) \geq H_{\infty}(X \oplus Y \mid Y) = H_{\infty}(X)$\mdline{344}
where the first inequality follows from the fact that we\mdline{345}'\mdline{345}re given more information and the second
inequality from the fact that given \mdline{346}$Y$\mdline{346}, the only unknown is \mdline{346}$X$\mdline{346}. With either explanation,
an exactly symetric argument for \mdline{347}$Y$\mdline{347} will show that:
\noindent\noindent\[%mdk-data-line={349}
\begin{aligned}
H_{\infty}(X \oplus Y) &\geq H_{\infty}(X) \\
H_{\infty}(X \oplus Y) &\geq H_{\infty}(Y) \\
\implies H_{\infty}(X \oplus Y) &\geq \max \{ H_{\infty}(X), H_{\infty}(Y)\}
\end{aligned}
\]%mdk
\mdline{355}as desired.%mdk

%mdk-data-line={356}
\item{}
%mdk-data-line={356}
\mdline{356}(10 points) Give an example of two distributions \mdline{356}$X$\mdline{356} and \mdline{356}$Y$\mdline{356} over \mdline{356}$\zo^n$\mdline{356} with min entropy \mdline{356}$n/2$\mdline{356} such that \mdline{356}$H_{\infty}(X\oplus Y)=n/2$\mdline{356}.%mdk
\mdline{358}Let \mdline{358}$X$\mdline{358} be the distribution that selects the string%mdk
%mdk
\end{enumerate}%mdk%mdk
%mdk
\end{enumerate}%mdk%mdk


\end{document}
